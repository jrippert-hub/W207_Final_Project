{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MIDS 207 Final Project\n",
    "### Team Members: Rick Chen, Julian Rippert, Jimmy Zhu\n",
    "### Model Type: K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# preprocessing and hyperparameter turning libraries\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.stats import uniform\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# KNN model and evaluation libraries\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Description\n",
    "\n",
    "The objective of this competition is to predict the probability that a customer does not pay back their credit card balance amount in the future based on their monthly customer profile. The target binary variable is calculated by observing 18 months performance window after the latest credit card statement, and if the customer does not pay due amount in 120 days after their latest statement date it is considered a default event.\n",
    "\n",
    "The dataset contains aggregated profile features for each customer at each statement date. Features are anonymized and normalized, and fall into the following general categories:\n",
    "\n",
    "D_* = Delinquency variables\n",
    "S_* = Spend variables\n",
    "P_* = Payment variables\n",
    "B_* = Balance variables\n",
    "R_* = Risk variables\n",
    "with the following features being categorical:\n",
    "\n",
    "['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68']\n",
    "\n",
    "Your task is to predict, for each customer_ID, the probability of a future payment default (target = 1).\n",
    "\n",
    "Note that the negative class has been subsampled for this dataset at 5%, and thus receives a 20x weighting in the scoring metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather('train_data.ftr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         customer_ID        S_2       P_2  \\\n",
      "0  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f... 2017-03-09  0.938477   \n",
      "1  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f... 2017-04-07  0.936523   \n",
      "2  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f... 2017-05-28  0.954102   \n",
      "3  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f... 2017-06-13  0.960449   \n",
      "4  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f... 2017-07-16  0.947266   \n",
      "\n",
      "       D_39       B_1       B_2       R_1       S_3      D_41       B_3  ...  \\\n",
      "0  0.001734  0.008728  1.006836  0.009224  0.124023  0.008774  0.004707  ...   \n",
      "1  0.005775  0.004925  1.000977  0.006153  0.126709  0.000798  0.002714  ...   \n",
      "2  0.091492  0.021652  1.009766  0.006817  0.123962  0.007599  0.009422  ...   \n",
      "3  0.002455  0.013687  1.002930  0.001372  0.117188  0.000685  0.005531  ...   \n",
      "4  0.002483  0.015190  1.000977  0.007607  0.117310  0.004654  0.009308  ...   \n",
      "\n",
      "   D_137  D_138     D_139     D_140     D_141  D_142     D_143     D_144  \\\n",
      "0    NaN    NaN  0.002426  0.003706  0.003819    NaN  0.000569  0.000610   \n",
      "1    NaN    NaN  0.003956  0.003166  0.005032    NaN  0.009575  0.005493   \n",
      "2    NaN    NaN  0.003269  0.007328  0.000427    NaN  0.003429  0.006985   \n",
      "3    NaN    NaN  0.006119  0.004517  0.003201    NaN  0.008423  0.006527   \n",
      "4    NaN    NaN  0.003672  0.004944  0.008888    NaN  0.001670  0.008125   \n",
      "\n",
      "      D_145  target  \n",
      "0  0.002674       0  \n",
      "1  0.009216       0  \n",
      "2  0.002604       0  \n",
      "3  0.009598       0  \n",
      "4  0.009827       0  \n",
      "\n",
      "[5 rows x 191 columns]\n",
      "(5531451, 191)\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that our data has over 5.5 million data points with 190 features (excluding our target variable)\n",
    "As this data is will be too large for processing and modelling will take too long, let's take a small sample of the dataset.\n",
    "We will take 10% of the dataset for just over 500 thousand datapoints and sort by date (S_2 column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac = 0.1)\n",
    "df = df.sort_values(by = 'S_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_2</th>\n",
       "      <th>D_39</th>\n",
       "      <th>B_1</th>\n",
       "      <th>B_2</th>\n",
       "      <th>R_1</th>\n",
       "      <th>S_3</th>\n",
       "      <th>D_41</th>\n",
       "      <th>B_3</th>\n",
       "      <th>D_42</th>\n",
       "      <th>D_43</th>\n",
       "      <th>...</th>\n",
       "      <th>D_137</th>\n",
       "      <th>D_138</th>\n",
       "      <th>D_139</th>\n",
       "      <th>D_140</th>\n",
       "      <th>D_141</th>\n",
       "      <th>D_142</th>\n",
       "      <th>D_143</th>\n",
       "      <th>D_144</th>\n",
       "      <th>D_145</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>714456</th>\n",
       "      <td>0.769043</td>\n",
       "      <td>0.505859</td>\n",
       "      <td>0.021439</td>\n",
       "      <td>0.810059</td>\n",
       "      <td>0.007526</td>\n",
       "      <td>0.139648</td>\n",
       "      <td>0.006222</td>\n",
       "      <td>0.086487</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.051422</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005733</td>\n",
       "      <td>0.005043</td>\n",
       "      <td>0.001645</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009499</td>\n",
       "      <td>0.005981</td>\n",
       "      <td>0.009201</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253753</th>\n",
       "      <td>0.941895</td>\n",
       "      <td>0.147339</td>\n",
       "      <td>0.045074</td>\n",
       "      <td>1.005859</td>\n",
       "      <td>0.001395</td>\n",
       "      <td>0.172852</td>\n",
       "      <td>0.009575</td>\n",
       "      <td>0.013054</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012032</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>0.003731</td>\n",
       "      <td>0.007896</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003036</td>\n",
       "      <td>0.009445</td>\n",
       "      <td>0.001812</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 189 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             P_2      D_39       B_1       B_2       R_1       S_3      D_41  \\\n",
       "714456  0.769043  0.505859  0.021439  0.810059  0.007526  0.139648  0.006222   \n",
       "253753  0.941895  0.147339  0.045074  1.005859  0.001395  0.172852  0.009575   \n",
       "\n",
       "             B_3  D_42      D_43  ...  D_137  D_138     D_139     D_140  \\\n",
       "714456  0.086487   NaN  0.051422  ...    NaN    NaN  0.005733  0.005043   \n",
       "253753  0.013054   NaN  0.012032  ...    NaN    NaN  0.000599  0.003731   \n",
       "\n",
       "           D_141  D_142     D_143     D_144     D_145  target  \n",
       "714456  0.001645    NaN  0.009499  0.005981  0.009201       0  \n",
       "253753  0.007896    NaN  0.003036  0.009445  0.001812       0  \n",
       "\n",
       "[2 rows x 189 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the customer ID and date columns as they won't be useful for modeling\n",
    "df = df.drop(columns = ['customer_ID', 'S_2'])\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop additional columns with high nan values per Julian's EDA\n",
    "del_cols = ['D_42', 'D_49', 'D_50', 'D_53', 'D_56', 'S_9', 'B_17', 'D_66', 'D_73', 'D_76', 'D_77', 'R_9', 'D_82', 'B_29',\n",
    "'D_87', 'D_88', 'D_105', 'D_106', 'R_26', 'D_108', 'D_110', 'D_111', 'B_39', 'B_42', 'D_132',\n",
    "'D_134', 'D_135', 'D_136', 'D_137', 'D_138', 'D_142']\n",
    "\n",
    "df = df.drop(columns = del_cols)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to impute values for our non-numerical categorical values, we'll encode them as numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D_63 before encoding:  0    411981\n",
      "1     92933\n",
      "2     43964\n",
      "3      2556\n",
      "4      1047\n",
      "5       664\n",
      "Name: D_63, dtype: int64\n",
      "D_64 before encoding:  1     292027\n",
      "2     151401\n",
      "3      84148\n",
      "4      21833\n",
      "-1      3736\n",
      "Name: D_64, dtype: int64\n",
      "D_63 after encoding:  0    411981\n",
      "1     92933\n",
      "2     43964\n",
      "3      2556\n",
      "4      1047\n",
      "5       664\n",
      "Name: D_63, dtype: int64\n",
      "D_64 after encoding: 1     292027\n",
      "2     151401\n",
      "3      84148\n",
      "4      21833\n",
      "-1      3736\n",
      "Name: D_64, dtype: int64\n",
      "714456     0\n",
      "253753     1\n",
      "2397731    1\n",
      "2090355    1\n",
      "793076     0\n",
      "          ..\n",
      "1182267    0\n",
      "4291363    2\n",
      "1923456    1\n",
      "5176163    0\n",
      "3594238    0\n",
      "Name: D_63, Length: 553145, dtype: category\n",
      "Categories (6, int64): [2, 0, 1, 5, 4, 3]\n"
     ]
    }
   ],
   "source": [
    "print('D_63 before encoding: ', df['D_63'].value_counts())\n",
    "print('D_64 before encoding: ', df['D_64'].value_counts())\n",
    "cat_map = {\"D_63\":  {\"CO\": 0, \"CR\": 1, \"CL\": 2, \"XZ\": 3, \"XM\": 4, \"XL\": 5},\n",
    "            \"D_64\": {\"O\": 1, \"U\": 2, \"R\": 3, '': 4 }}\n",
    "df = df.replace(cat_map)\n",
    "print('D_63 after encoding: ', df['D_63'].value_counts())\n",
    "print('D_64 after encoding:', df['D_64'].value_counts())\n",
    "print(df['D_63'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the remaining nan values in our dataset. We'll impute the value that is assigned using KNN with 5 neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P_2        4646\n",
       "D_39          0\n",
       "B_1           0\n",
       "B_2         211\n",
       "R_1           0\n",
       "          ...  \n",
       "D_141     10238\n",
       "D_143     10238\n",
       "D_144      4016\n",
       "D_145     10238\n",
       "target        0\n",
       "Length: 158, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jimmy Zhu\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n"
     ]
    }
   ],
   "source": [
    "df2 = df[['D_63', 'D_64']]\n",
    "df1 = df.drop(columns = ['D_63', 'D_64'])\n",
    "\n",
    "columns1 = df1.columns\n",
    "columns2 = df2.columns\n",
    "imp1 = SimpleImputer(missing_values=np.NaN)\n",
    "imp2 = SimpleImputer(missing_values = np.NaN, strategy = 'most_frequent')\n",
    "df1 = pd.DataFrame(imp.fit_transform(df1))\n",
    "df2 = pd.DataFrame(imp.fit_transform(df2))\n",
    "df2.columns = columns2\n",
    "df1.columns = columns1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jimmy Zhu\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jimmy Zhu\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df['D_63'] = d_63\n",
    "df['D_64'] = d_64\n",
    "imp=SimpleImputer(missing_values=np.NaN, strategy = 'most_frequent')\n",
    "df=pd.DataFrame(imp.fit_transform(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P_2       0\n",
       "D_39      0\n",
       "B_1       0\n",
       "B_2       0\n",
       "R_1       0\n",
       "         ..\n",
       "D_144     0\n",
       "D_145     0\n",
       "target    0\n",
       "D_63      0\n",
       "D_64      0\n",
       "Length: 158, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = pd.concat([df1, df2], axis = 1)\n",
    "df_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['B_1', 'B_10', 'B_11', 'B_12', 'B_13', 'B_14', 'B_15', 'B_16', 'B_18',\n",
      "       'B_19',\n",
      "       ...\n",
      "       'S_24', 'S_25', 'S_26', 'S_27', 'S_3', 'S_5', 'S_6', 'S_7', 'S_8',\n",
      "       'target'],\n",
      "      dtype='object', length=158)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B_1</th>\n",
       "      <th>B_10</th>\n",
       "      <th>B_11</th>\n",
       "      <th>B_12</th>\n",
       "      <th>B_13</th>\n",
       "      <th>B_14</th>\n",
       "      <th>B_15</th>\n",
       "      <th>B_16</th>\n",
       "      <th>B_18</th>\n",
       "      <th>B_19</th>\n",
       "      <th>...</th>\n",
       "      <th>S_24</th>\n",
       "      <th>S_25</th>\n",
       "      <th>S_26</th>\n",
       "      <th>S_27</th>\n",
       "      <th>S_3</th>\n",
       "      <th>S_5</th>\n",
       "      <th>S_6</th>\n",
       "      <th>S_7</th>\n",
       "      <th>S_8</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.889648</td>\n",
       "      <td>0.213135</td>\n",
       "      <td>0.0168</td>\n",
       "      <td>1.001953</td>\n",
       "      <td>0.00658</td>\n",
       "      <td>0.107727</td>\n",
       "      <td>0.004398</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>0.051575</td>\n",
       "      <td>0.006981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.009659</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.00526</td>\n",
       "      <td>0.001027</td>\n",
       "      <td>0.001487</td>\n",
       "      <td>0.003918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.450439</td>\n",
       "      <td>0.266357</td>\n",
       "      <td>0.027985</td>\n",
       "      <td>1.005859</td>\n",
       "      <td>0.006554</td>\n",
       "      <td>0.069641</td>\n",
       "      <td>0.004959</td>\n",
       "      <td>0.009064</td>\n",
       "      <td>0.028763</td>\n",
       "      <td>0.118515</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006416</td>\n",
       "      <td>0.004494</td>\n",
       "      <td>0.002565</td>\n",
       "      <td>0.003717</td>\n",
       "      <td>0.00214</td>\n",
       "      <td>0.006191</td>\n",
       "      <td>0.006012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.221802</td>\n",
       "      <td>0.388916</td>\n",
       "      <td>0.211304</td>\n",
       "      <td>0.010834</td>\n",
       "      <td>0.003588</td>\n",
       "      <td>0.496338</td>\n",
       "      <td>0.006454</td>\n",
       "      <td>0.215332</td>\n",
       "      <td>0.493408</td>\n",
       "      <td>0.129883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001792</td>\n",
       "      <td>0.003218</td>\n",
       "      <td>0.006783</td>\n",
       "      <td>0.001347</td>\n",
       "      <td>0.003843</td>\n",
       "      <td>0.006901</td>\n",
       "      <td>0.003092</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.235596</td>\n",
       "      <td>0.017776</td>\n",
       "      <td>0.48999</td>\n",
       "      <td>0.001529</td>\n",
       "      <td>0.335938</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.027405</td>\n",
       "      <td>0.005035</td>\n",
       "      <td>0.001378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007076</td>\n",
       "      <td>0.002264</td>\n",
       "      <td>0.007904</td>\n",
       "      <td>0.001025</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.001878</td>\n",
       "      <td>0.009796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.552734</td>\n",
       "      <td>0.503418</td>\n",
       "      <td>0.359863</td>\n",
       "      <td>0.039307</td>\n",
       "      <td>0.001715</td>\n",
       "      <td>0.165405</td>\n",
       "      <td>0.008209</td>\n",
       "      <td>0.331543</td>\n",
       "      <td>0.009781</td>\n",
       "      <td>0.506836</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>0.004333</td>\n",
       "      <td>0.007607</td>\n",
       "      <td>0.002146</td>\n",
       "      <td>0.006802</td>\n",
       "      <td>0.006981</td>\n",
       "      <td>0.006317</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 158 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        B_1      B_10      B_11      B_12      B_13      B_14      B_15  \\\n",
       "0  0.889648  0.213135    0.0168  1.001953   0.00658  0.107727  0.004398   \n",
       "1  0.450439  0.266357  0.027985  1.005859  0.006554  0.069641  0.004959   \n",
       "2  0.221802  0.388916  0.211304  0.010834  0.003588  0.496338  0.006454   \n",
       "3  0.984375  0.235596  0.017776   0.48999  0.001529  0.335938  0.000094   \n",
       "4  0.552734  0.503418  0.359863  0.039307  0.001715  0.165405  0.008209   \n",
       "\n",
       "       B_16      B_18      B_19  ...      S_24      S_25      S_26      S_27  \\\n",
       "0  0.000887  0.051575  0.006981  ...  0.000305  0.009659  0.000241   0.00526   \n",
       "1  0.009064  0.028763  0.118515  ...  0.006416  0.004494  0.002565  0.003717   \n",
       "2  0.215332  0.493408  0.129883  ...  0.001792  0.003218  0.006783  0.001347   \n",
       "3  0.027405  0.005035  0.001378  ...  0.007076  0.002264  0.007904  0.001025   \n",
       "4  0.331543  0.009781  0.506836  ...  0.001105  0.004333  0.007607  0.002146   \n",
       "\n",
       "        S_3       S_5       S_6  S_7 S_8 target  \n",
       "0  0.001027  0.001487  0.003918  0.0   1      1  \n",
       "1   0.00214  0.006191  0.006012  0.0   1      1  \n",
       "2  0.003843  0.006901  0.003092  1.0   0      1  \n",
       "3  0.000427  0.001878  0.009796  0.0   0      1  \n",
       "4  0.006802  0.006981  0.006317  1.0   0      1  \n",
       "\n",
       "[5 rows x 158 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "columns = columns.union(['D_63', 'D_64'])\n",
    "print(columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#df.columns = columns\n",
    "\n",
    "X = df_clean.drop(columns = ['target'])\n",
    "Y = df_clean['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, shuffle = False, random_state = 4)\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.25, shuffle = False, random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(331887, 157) (331887,)\n",
      "(110629, 157) (110629,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_val.shape, Y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering and PCA\n",
    "\n",
    "As KNN models are more efficient with less features, we will want to reduce the number of features in our model. A lot of this analysis was borrowed from Julian Rippert's feature engineering section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 15)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_val_pca = pca.fit_transform(X_val)\n",
    "X_test_pca = pca.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(331887, 15) (110629, 15) (110629, 15)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_pca.shape, X_val_pca.shape, X_test_pca.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model\n",
    "\n",
    "A KNN model is a very simple model that looks at the distance (generally based off the euclidean distance) from neighboring points. Based off the distance between neighboring points, the model will determine how to classify the value of question by a simple majority. Therefore if we are looking at the nearest 3 neighbors like the example below, and a majority of the closest neighbors are class B, then we will classify this point as class B as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![KNN Model](image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train_pca, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.74      0.74     82208\n",
      "         1.0       0.24      0.24      0.24     28421\n",
      "\n",
      "    accuracy                           0.61    110629\n",
      "   macro avg       0.49      0.49      0.49    110629\n",
      "weighted avg       0.61      0.61      0.61    110629\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    Y_pred = knn.predict(X_test_pca)\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run gridsearchcv to cross validate and search for the model with the best hyperparameters. I only adjust the number of neighbors as adding other hyperparameters takes really long (10s of hours). Other hyperparameters woth adjusting include the p value and the leaf node size.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = list(range(1, 50))\n",
    "hyperparameters = dict(n_neighbors = n_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    knn_2 = KNeighborsClassifier()\n",
    "    clf = GridSearchCV(knn_2, hyperparameters, cv = 10, n_jobs = -1)\n",
    "    best_model = clf.fit(X_train_pca, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best leafsize: 30\n",
      "Best n_neighbors: 27\n"
     ]
    }
   ],
   "source": [
    "print('Best leafsize:' , best_model.best_estimator_.get_params()['leaf_size'])\n",
    "print('Best n_neighbors:' , best_model.best_estimator_.get_params()['n_neighbors'])\n",
    "#print('Best p:' , best_model.best_estimator_.get_params()['p'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that the optimal number number of neighbors for our KNN model is 29. Let's use that to build a KNN model on our training data and test it against our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jimmy Zhu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.84      0.79     82208\n",
      "         1.0       0.27      0.17      0.21     28421\n",
      "\n",
      "    accuracy                           0.67    110629\n",
      "   macro avg       0.51      0.50      0.50    110629\n",
      "weighted avg       0.62      0.67      0.64    110629\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_best = KNeighborsClassifier(leaf_size =30, n_neighbors = 27)\n",
    "knn_best.fit(X_train_pca, Y_train)\n",
    "Y_pred = knn_best.predict(X_test_pca)\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission file on Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to create the submission file:\n",
    "The sample submission file asks us to create a csv file with a list of each customer_ID and a corresponding binary value indicating whether or not they will default.\n",
    "\n",
    "I had trouble running this on my personal computer, so I have put in skeleton code without running it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>S_2</th>\n",
       "      <th>P_2</th>\n",
       "      <th>D_39</th>\n",
       "      <th>B_1</th>\n",
       "      <th>B_2</th>\n",
       "      <th>R_1</th>\n",
       "      <th>S_3</th>\n",
       "      <th>D_41</th>\n",
       "      <th>B_3</th>\n",
       "      <th>...</th>\n",
       "      <th>D_136</th>\n",
       "      <th>D_137</th>\n",
       "      <th>D_138</th>\n",
       "      <th>D_139</th>\n",
       "      <th>D_140</th>\n",
       "      <th>D_141</th>\n",
       "      <th>D_142</th>\n",
       "      <th>D_143</th>\n",
       "      <th>D_144</th>\n",
       "      <th>D_145</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000469ba478561f23a92a868bd366de6f6527a684c9a...</td>\n",
       "      <td>2019-02-19</td>\n",
       "      <td>0.631348</td>\n",
       "      <td>0.001912</td>\n",
       "      <td>0.010727</td>\n",
       "      <td>0.814453</td>\n",
       "      <td>0.007545</td>\n",
       "      <td>0.168701</td>\n",
       "      <td>0.009972</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004669</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008278</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000469ba478561f23a92a868bd366de6f6527a684c9a...</td>\n",
       "      <td>2019-03-25</td>\n",
       "      <td>0.586914</td>\n",
       "      <td>0.005276</td>\n",
       "      <td>0.011024</td>\n",
       "      <td>0.811035</td>\n",
       "      <td>0.001817</td>\n",
       "      <td>0.241333</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.009132</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.004940</td>\n",
       "      <td>0.009018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003695</td>\n",
       "      <td>0.003754</td>\n",
       "      <td>0.001460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000469ba478561f23a92a868bd366de6f6527a684c9a...</td>\n",
       "      <td>2019-04-25</td>\n",
       "      <td>0.608887</td>\n",
       "      <td>0.003326</td>\n",
       "      <td>0.016388</td>\n",
       "      <td>1.004883</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.267090</td>\n",
       "      <td>0.004196</td>\n",
       "      <td>0.004192</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.002113</td>\n",
       "      <td>0.004658</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003155</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>0.006481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000469ba478561f23a92a868bd366de6f6527a684c9a...</td>\n",
       "      <td>2019-05-20</td>\n",
       "      <td>0.614746</td>\n",
       "      <td>0.009064</td>\n",
       "      <td>0.021667</td>\n",
       "      <td>0.816406</td>\n",
       "      <td>0.009720</td>\n",
       "      <td>0.188965</td>\n",
       "      <td>0.004124</td>\n",
       "      <td>0.015327</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004742</td>\n",
       "      <td>0.006393</td>\n",
       "      <td>0.002890</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006042</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>0.007858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000469ba478561f23a92a868bd366de6f6527a684c9a...</td>\n",
       "      <td>2019-06-15</td>\n",
       "      <td>0.591797</td>\n",
       "      <td>0.238770</td>\n",
       "      <td>0.015930</td>\n",
       "      <td>0.810547</td>\n",
       "      <td>0.002026</td>\n",
       "      <td>0.180054</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>0.011284</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008133</td>\n",
       "      <td>0.004330</td>\n",
       "      <td>0.008385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.007420</td>\n",
       "      <td>0.009468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 190 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_ID        S_2       P_2  \\\n",
       "0  00000469ba478561f23a92a868bd366de6f6527a684c9a... 2019-02-19  0.631348   \n",
       "1  00000469ba478561f23a92a868bd366de6f6527a684c9a... 2019-03-25  0.586914   \n",
       "2  00000469ba478561f23a92a868bd366de6f6527a684c9a... 2019-04-25  0.608887   \n",
       "3  00000469ba478561f23a92a868bd366de6f6527a684c9a... 2019-05-20  0.614746   \n",
       "4  00000469ba478561f23a92a868bd366de6f6527a684c9a... 2019-06-15  0.591797   \n",
       "\n",
       "       D_39       B_1       B_2       R_1       S_3      D_41       B_3  ...  \\\n",
       "0  0.001912  0.010727  0.814453  0.007545  0.168701  0.009972  0.002348  ...   \n",
       "1  0.005276  0.011024  0.811035  0.001817  0.241333  0.000166  0.009132  ...   \n",
       "2  0.003326  0.016388  1.004883  0.000114  0.267090  0.004196  0.004192  ...   \n",
       "3  0.009064  0.021667  0.816406  0.009720  0.188965  0.004124  0.015327  ...   \n",
       "4  0.238770  0.015930  0.810547  0.002026  0.180054  0.000731  0.011284  ...   \n",
       "\n",
       "   D_136  D_137  D_138     D_139     D_140     D_141  D_142     D_143  \\\n",
       "0    NaN    NaN    NaN       NaN  0.004669       NaN    NaN       NaN   \n",
       "1    NaN    NaN    NaN  0.000142  0.004940  0.009018    NaN  0.003695   \n",
       "2    NaN    NaN    NaN  0.000074  0.002113  0.004658    NaN  0.003155   \n",
       "3    NaN    NaN    NaN  0.004742  0.006393  0.002890    NaN  0.006042   \n",
       "4    NaN    NaN    NaN  0.008133  0.004330  0.008385    NaN  0.001008   \n",
       "\n",
       "      D_144     D_145  \n",
       "0  0.008278       NaN  \n",
       "1  0.003754  0.001460  \n",
       "2  0.002155  0.006481  \n",
       "3  0.005207  0.007858  \n",
       "4  0.007420  0.009468  \n",
       "\n",
       "[5 rows x 190 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_feather('test_data.ftr')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = df_test.pop('customer_ID')\n",
    "del_cols = ['D_42', 'D_49', 'D_50', 'D_53', 'D_56', 'S_9', 'B_17', 'D_66', 'D_73', 'D_76', 'D_77', 'R_9', 'D_82', 'B_29',\n",
    "'D_87', 'D_88', 'D_105', 'D_106', 'R_26', 'D_108', 'D_110', 'D_111', 'B_39', 'B_42', 'D_132',\n",
    "'D_134', 'D_135', 'D_136', 'D_137', 'D_138', 'D_142', 'S_2']\n",
    "\n",
    "df = df.drop(columns = del_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the model trained fit on the training data, and apply it to the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pred = knn.predict(df['target'])\n",
    "submission_df = pd.concat([ids, Y_test_pred])\n",
    "submission_df.to_csv(file_name, sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
